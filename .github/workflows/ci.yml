name: Python CI/CD with DVC

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11"]

    steps:
    # 1. Checkout
    - name: Checkout repository
      uses: actions/checkout@v3

    # 2. Setup Python
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    # 3. Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install flake8 pytest
        pip install dvc[s3]

    # 4. Lint
    - name: Lint with flake8
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

    # 5. Tests
    - name: Run pytest
      run: pytest || echo "No tests yet"

    # 6. Pull data + models from DVC remote
    - name: DVC Pull
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: dvc pull -r myremote

    # 7.1 Start MLflow Tracking Server
    - name: Start MLflow Tracking Server
      run: nohup mlflow server --host 127.0.0.1 --port 5000 &

    # 7.2 Wait for MLflow to be ready
    - name: Wait for MLflow to be ready
      run: |
        for i in {1..10}; do
          nc -z 127.0.0.1 5000 && break
          sleep 1
        done

    # 7.3 Run pipeline (training + metrics logging)
    - name: DVC Repro
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: dvc repro

    # 8. Verify metrics exist
    - name: Verify metrics
      run: |
        if [ ! -f data/baseline_metrics.csv ]; then
          echo "❌ baseline_metrics.csv missing"; exit 1;
        fi
        if [ ! -f data/last_run_metrics.json ]; then
          echo "❌ last_run_metrics.json missing"; exit 1;
        fi
        echo "✅ Metrics files found"

    # 9. Push DVC cache (models/dataset) to S3
    - name: DVC Push 
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: dvc push -r myremote


    # 10. Show latest metrics in logs
    - name: Show metrics summary
      run: cat data/last_run_metrics.json || echo "Metrics file not found"
